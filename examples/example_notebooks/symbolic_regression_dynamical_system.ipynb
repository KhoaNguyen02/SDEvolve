{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic regression of a dynamical system\n",
    "\n",
    "In this example, Kozax is applied to recover the state equations of the Lotka-Volterra system. The candidate solutions are integrated as a system of differential equations, after which the predictions are compared to the true observations to determine a fitness score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These device(s) are detected:  [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7), CpuDevice(id=8), CpuDevice(id=9)]\n"
     ]
    }
   ],
   "source": [
    "# Specify the cores to use for XLA\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=10'\n",
    "\n",
    "import jax\n",
    "import diffrax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import diffrax\n",
    "\n",
    "from kozax.genetic_programming import GeneticProgramming\n",
    "from kozax.fitness_functions.ODE_fitness_function import ODEFitnessFunction\n",
    "from kozax.environments.SR_environments.lotka_volterra import LotkaVolterra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data is generated, consisting of initial conditions, time points and the true observations. Kozax provides the Lotka-Volterra environment, which is integrated with Diffrax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(key, env, dt, T, batch_size=20):\n",
    "    x0s = env.sample_init_states(batch_size, key)\n",
    "    ts = jnp.arange(0, T, dt)\n",
    "\n",
    "    def solve(env, ts, x0):\n",
    "        solver = diffrax.Dopri5()\n",
    "        dt0 = 0.001\n",
    "        saveat = diffrax.SaveAt(ts=ts)\n",
    "\n",
    "        system = diffrax.ODETerm(env.drift)\n",
    "\n",
    "        # Solve the system given an initial conditions\n",
    "        sol = diffrax.diffeqsolve(system, solver, ts[0], ts[-1], dt0, x0, saveat=saveat, max_steps=500, \n",
    "                                  adjoint=diffrax.DirectAdjoint(), stepsize_controller=diffrax.PIDController(atol=1e-7, rtol=1e-7, dtmin=0.001))\n",
    "        \n",
    "        return sol.ys\n",
    "\n",
    "    ys = jax.vmap(solve, in_axes=[None, None, 0])(env, ts, x0s) #Parallelize over the batch dimension\n",
    "    \n",
    "    return x0s, ts, ys\n",
    "\n",
    "key = jr.PRNGKey(0)\n",
    "data_key, gp_key = jr.split(key)\n",
    "\n",
    "T = 30\n",
    "dt = 0.2\n",
    "env = LotkaVolterra()\n",
    "\n",
    "# Simulate the data\n",
    "data = get_data(data_key, env, dt, T, batch_size=4)\n",
    "x0s, ts, ys = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fitness function, we used the ODEFitnessFunction that uses Diffrax to integrate candidate solutions. It is possible to select the solver, time step, number of steps and a stepsize controller to balance efficiency and accuracy. To ensure convergence of the genetic programming algorithm, constant optimization is applied to the best candidates at every generation. The constant optimization is performed with a couple of simple evolutionary steps that adjust the values of the constants in a candidate. The hyperparameters that define the constant optimization are `constant_optimization_N_offspring` (number of candidates with different constants should be sampled for each candidate), `constant_optimization_steps` (number of iterations of constant optimization for each candidate), `optimize_constants_elite` (number of candidates that constant optimization is applied to), `constant_step_size_init` (initial value of the step size for sampling constants) and `constant_step_size_decay` (the rate of decrease of the step size over generations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data should be formatted as: ['x0', 'x1'].\n"
     ]
    }
   ],
   "source": [
    "#Define the nodes and hyperparameters\n",
    "operator_list = [\n",
    "        (\"+\", lambda x, y: jnp.add(x, y), 2, 0.5), \n",
    "        (\"-\", lambda x, y: jnp.subtract(x, y), 2, 0.1), \n",
    "        (\"*\", lambda x, y: jnp.multiply(x, y), 2, 0.5), \n",
    "    ]\n",
    "\n",
    "variable_list = [[\"x\" + str(i) for i in range(env.n_var)]]\n",
    "layer_sizes = jnp.array([env.n_var])\n",
    "\n",
    "population_size = 100\n",
    "num_populations = 10\n",
    "num_generations = 50\n",
    "\n",
    "#Initialize the fitness function and the genetic programming strategy\n",
    "fitness_function = ODEFitnessFunction(solver=diffrax.Dopri5(), dt0 = 0.01, stepsize_controller=diffrax.PIDController(atol=1e-6, rtol=1e-6, dtmin=0.001), max_steps=300)\n",
    "\n",
    "strategy = GeneticProgramming(num_generations, population_size, fitness_function, operator_list, variable_list, layer_sizes, num_populations = num_populations,\n",
    "                        size_parsimony=0.003, constant_optimization_method=\"evolution\", constant_optimization_N_offspring = 25, constant_optimization_steps = 5, \n",
    "                        optimize_constants_elite=100, constant_step_size_init=0.1, constant_step_size_decay=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kozax provides a fit function that receives the data and a random key. However, it is also possible to run Kozax with an easy loop consisting of evaluating and evolving. This is useful as different input data can be provided during evaluation. In symbolic regression of dynamical systems, it helps to first optimize on a small part of the time points, and provide the full data trajectories only after a couple of generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generation 1, best fitness = 0.8547, best solution = [-0.414*x0*x1 + x0, 0.446*x0 - 0.377*x1]\n",
      "In generation 2, best fitness = 0.8428, best solution = [-0.381*x0*x1 + x0, 0.422*x0 - 0.361*x1]\n",
      "In generation 3, best fitness = 0.8428, best solution = [-0.381*x0*x1 + x0, 0.422*x0 - 0.361*x1]\n",
      "In generation 4, best fitness = 0.8397, best solution = [-0.397*x0*x1 + x0, 0.374*x0 - 0.356*x1]\n",
      "In generation 5, best fitness = 0.7787, best solution = [-1.28*x0*(0.302*x1 - 0.888), 0.315*x0 - 0.21*x1 - 0.391]\n",
      "In generation 6, best fitness = 0.6935, best solution = [-1.54*x0*(0.293*x1 - 0.819), 0.285*x0 - 0.233*x1 - 0.358]\n",
      "In generation 7, best fitness = 0.6935, best solution = [-1.54*x0*(0.293*x1 - 0.819), 0.285*x0 - 0.233*x1 - 0.358]\n",
      "In generation 8, best fitness = 0.6689, best solution = [-1.68*x0*(0.305*x1 - 0.793), 0.244*x0 - 0.233*x1 - 0.354]\n",
      "In generation 9, best fitness = 0.6648, best solution = [-1.36*x0*(0.35*x1 - 0.989), 0.238*x0 - 0.22*x1 - 0.343]\n",
      "In generation 10, best fitness = 0.6648, best solution = [-1.36*x0*(0.35*x1 - 0.989), 0.238*x0 - 0.22*x1 - 0.343]\n",
      "In generation 11, best fitness = 0.6570, best solution = [-1.2*x0*(0.391*x1 - 1.0), 0.237*x0 - 0.237*x1 - 0.377]\n",
      "In generation 12, best fitness = 0.6532, best solution = [-1.53*x0*(0.322*x1 - 0.871), 0.214*x0 - 0.229*x1 - 0.317]\n",
      "In generation 13, best fitness = 0.6511, best solution = [-1.5*x0*(0.302*x1 - 0.837), 0.208*x0 - 0.238*x1 - 0.288]\n",
      "In generation 14, best fitness = 0.6502, best solution = [-1.47*x0*(0.325*x1 - 0.902), 0.187*x0 - 0.237*x1 - 0.264]\n",
      "In generation 15, best fitness = 0.6411, best solution = [-1.86*x0*(0.264*x1 - 0.677), 0.199*x0 - 0.253*x1 - 0.306]\n",
      "In generation 16, best fitness = 0.6411, best solution = [-1.86*x0*(0.264*x1 - 0.677), 0.199*x0 - 0.253*x1 - 0.306]\n",
      "In generation 17, best fitness = 0.6392, best solution = [-1.97*x0*(0.249*x1 - 0.664), 0.198*x0 - 0.248*x1 - 0.274]\n",
      "In generation 18, best fitness = 0.6392, best solution = [-1.97*x0*(0.249*x1 - 0.664), 0.198*x0 - 0.248*x1 - 0.274]\n",
      "In generation 19, best fitness = 0.6392, best solution = [-1.97*x0*(0.249*x1 - 0.664), 0.198*x0 - 0.248*x1 - 0.274]\n",
      "In generation 20, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 21, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 22, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 23, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 24, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 25, best fitness = 0.1253, best solution = [-0.402*x0*(x1 - 2.7), 0.102*x0*x1 - 0.41*x1]\n",
      "In generation 26, best fitness = 0.1691, best solution = [-0.398*x0*(x1 - 2.69), 0.0946*x0*x1 - 0.408*x1]\n",
      "In generation 27, best fitness = 0.1691, best solution = [-0.398*x0*(x1 - 2.69), 0.0946*x0*x1 - 0.408*x1]\n",
      "In generation 28, best fitness = 0.1691, best solution = [-0.398*x0*(x1 - 2.69), 0.0946*x0*x1 - 0.408*x1]\n",
      "In generation 29, best fitness = 0.1691, best solution = [-0.398*x0*(x1 - 2.69), 0.0946*x0*x1 - 0.408*x1]\n",
      "In generation 30, best fitness = 0.1691, best solution = [-0.398*x0*(x1 - 2.69), 0.0946*x0*x1 - 0.408*x1]\n",
      "In generation 31, best fitness = 0.1032, best solution = [-0.403*x0*(x1 - 2.72), 0.0978*x0*x1 - 0.401*x1]\n",
      "In generation 32, best fitness = 0.1032, best solution = [-0.403*x0*(x1 - 2.72), 0.0978*x0*x1 - 0.401*x1]\n",
      "In generation 33, best fitness = 0.1032, best solution = [-0.403*x0*(x1 - 2.72), 0.0978*x0*x1 - 0.401*x1]\n",
      "In generation 34, best fitness = 0.1032, best solution = [-0.403*x0*(x1 - 2.72), 0.0978*x0*x1 - 0.401*x1]\n",
      "In generation 35, best fitness = 0.1032, best solution = [-0.403*x0*(x1 - 2.72), 0.0978*x0*x1 - 0.401*x1]\n",
      "In generation 36, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 37, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 38, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 39, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 40, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 41, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 42, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 43, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 44, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 45, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 46, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 47, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 48, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 49, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n",
      "In generation 50, best fitness = 0.0934, best solution = [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n"
     ]
    }
   ],
   "source": [
    "# Sample the initial population\n",
    "population = strategy.initialize_population(gp_key)\n",
    "\n",
    "# Define the number of timepoints to include in the data\n",
    "end_ts = int(ts.shape[0]/2)\n",
    "\n",
    "for g in range(num_generations):\n",
    "    if g == 25: # After 25 generations, use the full data\n",
    "        end_ts = ts.shape[0]\n",
    "\n",
    "    key, eval_key, sample_key = jr.split(key, 3)\n",
    "    # Evaluate the population on the data, and return the fitness\n",
    "    fitness, population = strategy.evaluate_population(population, (x0s, ts[:end_ts], ys[:,:end_ts]), eval_key)\n",
    "\n",
    "    # Print the best solution in the population in this generation\n",
    "    best_fitness, best_solution = strategy.get_statistics(g)\n",
    "    print(f\"In generation {g+1}, best fitness = {best_fitness:.4f}, best solution = {strategy.expression_to_string(best_solution)}\")\n",
    "\n",
    "    # Evolve the population until the last generation. The fitness should be given to the evolve function.\n",
    "    if g < (num_generations-1):\n",
    "        population = strategy.evolve_population(population, fitness, sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: 2, fitness: 3.603614091873169, equations: [-0.0703, -0.395]\n",
      "Complexity: 4, fitness: 2.3969385623931885, equations: [-1.09*x0, -0.715]\n",
      "Complexity: 6, fitness: 1.2524828910827637, equations: [-1.38*x0, -0.327*x1]\n",
      "Complexity: 8, fitness: 1.1349678039550781, equations: [-2.74*x0, x0 - 0.432*x1]\n",
      "Complexity: 10, fitness: 1.1001994609832764, equations: [-2.91*x0, x0 - 0.427*x1 + 0.0944]\n",
      "Complexity: 12, fitness: 1.0081340074539185, equations: [-0.44*x0*(x0 + x1 - 3.0), -0.318*x1]\n",
      "Complexity: 14, fitness: 0.749535083770752, equations: [-0.402*x0*x1 + x0, 0.229*x0 - 0.366*x1]\n",
      "Complexity: 16, fitness: 0.6201074123382568, equations: [-0.449*x0*(x1 - 2.82), 0.0934*x0*x1 - 0.382*x1]\n",
      "Complexity: 18, fitness: 0.08289898931980133, equations: [-0.408*x0*(x1 - 2.82), 0.0934*x0*x1 - 0.382*x1]\n",
      "Complexity: 20, fitness: 0.033442918211221695, equations: [-0.407*x0*(x1 - 2.74), 0.102*x0*x1 - 0.401*x1]\n"
     ]
    }
   ],
   "source": [
    "strategy.print_pareto_front()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using evolution to optimize the constants, Kozax also offers gradient-based optimization. For gradient optimization, it is possible to specify the optimizer, the number of candidates to apply constant optimization to, the initial learning rate and the learning rate decay over generation. These two methods are provided as either can be more effective or efficient for different problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data should be formatted as: ['x0', 'x1'].\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "\n",
    "strategy = GeneticProgramming(num_generations, population_size, fitness_function, operator_list, variable_list, layer_sizes, num_populations = num_populations,\n",
    "                        size_parsimony=0.003, constant_optimization_method=\"gradient\", constant_optimization_steps = 15, optimizer_class = optax.adam,\n",
    "                        optimize_constants_elite=100, constant_step_size_init=0.01, constant_step_size_decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generation 1, best fitness = 0.8637, best solution = [-0.394*x0*x1 + x0, 0.529*x0 - 0.367*x1]\n",
      "In generation 2, best fitness = 0.8579, best solution = [-0.393*x0*x1 + x0, 0.525*x0 - 0.372*x1]\n",
      "In generation 3, best fitness = 0.7924, best solution = [-0.407*x0*x1 + x0, 0.185*x0 - 0.36*x1]\n",
      "In generation 4, best fitness = 0.7923, best solution = [-0.403*x0*x1 + x0, 0.182*x0 - 0.357*x1]\n",
      "In generation 5, best fitness = 0.7918, best solution = [-0.402*x0*x1 + x0, 0.182*x0 - 0.359*x1]\n",
      "In generation 6, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 7, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 8, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 9, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 10, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 11, best fitness = 0.7913, best solution = [-0.403*x0*x1 + x0, 0.184*x0 - 0.359*x1]\n",
      "In generation 12, best fitness = 0.7709, best solution = [-2.31*x0*(0.202*x1 - 0.51), 0.235*x0 - 0.35*x1]\n",
      "In generation 13, best fitness = 0.4525, best solution = [-0.517*x0*(x1 - 2.46), 0.159*x0*x1 - 0.449*x1]\n",
      "In generation 14, best fitness = 0.2511, best solution = [-0.45*x0*(x1 - 2.48), 0.111*x0*x1 - 0.433*x1]\n",
      "In generation 15, best fitness = 0.1892, best solution = [-0.426*x0*(x1 - 2.5), 0.112*x0*x1 - 0.442*x1]\n",
      "In generation 16, best fitness = 0.1718, best solution = [-0.416*x0*(x1 - 2.52), 0.113*x0*x1 - 0.443*x1]\n",
      "In generation 17, best fitness = 0.1654, best solution = [-0.411*x0*(x1 - 2.53), 0.111*x0*x1 - 0.44*x1]\n",
      "In generation 18, best fitness = 0.1252, best solution = [-0.394*x0*(x1 - 2.87), 0.0928*x0*x1 - 0.378*x1]\n",
      "In generation 19, best fitness = 0.1065, best solution = [-0.406*x0*(x1 - 2.77), 0.0983*x0*x1 - 0.395*x1]\n",
      "In generation 20, best fitness = 0.0885, best solution = [-0.4*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.396*x1]\n",
      "In generation 21, best fitness = 0.0771, best solution = [-0.401*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.397*x1]\n",
      "In generation 22, best fitness = 0.0771, best solution = [-0.401*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.397*x1]\n",
      "In generation 23, best fitness = 0.0771, best solution = [-0.401*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.397*x1]\n",
      "In generation 24, best fitness = 0.0771, best solution = [-0.401*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.397*x1]\n",
      "In generation 25, best fitness = 0.0771, best solution = [-0.401*x0*(x1 - 2.77), 0.0996*x0*x1 - 0.397*x1]\n",
      "In generation 26, best fitness = 0.0771, best solution = [-0.399*x0*(x1 - 2.76), 0.1*x0*x1 - 0.399*x1]\n",
      "In generation 27, best fitness = 0.0721, best solution = [-0.4*x0*(x1 - 2.76), 0.0994*x0*x1 - 0.398*x1]\n",
      "In generation 28, best fitness = 0.0721, best solution = [-0.4*x0*(x1 - 2.76), 0.0994*x0*x1 - 0.398*x1]\n",
      "In generation 29, best fitness = 0.0721, best solution = [-0.4*x0*(x1 - 2.76), 0.0994*x0*x1 - 0.398*x1]\n",
      "In generation 30, best fitness = 0.0721, best solution = [-0.4*x0*(x1 - 2.76), 0.0994*x0*x1 - 0.398*x1]\n",
      "In generation 31, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 32, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 33, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 34, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 35, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 36, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 37, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 38, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 39, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 40, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 41, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 42, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 43, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 44, best fitness = 0.0680, best solution = [-0.399*x0*(x1 - 2.77), 0.1*x0*x1 - 0.398*x1]\n",
      "In generation 45, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "In generation 46, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "In generation 47, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "In generation 48, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "In generation 49, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "In generation 50, best fitness = 0.0618, best solution = [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n"
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "data_key, gp_key = jr.split(key)\n",
    "\n",
    "T = 30\n",
    "dt = 0.2\n",
    "env = LotkaVolterra()\n",
    "\n",
    "# Simulate the data\n",
    "data = get_data(data_key, env, dt, T, batch_size=4)\n",
    "x0s, ts, ys = data\n",
    "\n",
    "# Sample the initial population\n",
    "population = strategy.initialize_population(gp_key)\n",
    "\n",
    "# Define the number of timepoints to include in the data\n",
    "end_ts = int(ts.shape[0]/2)\n",
    "\n",
    "for g in range(num_generations):\n",
    "    if g == 25: # After 25 generations, use the full data\n",
    "        end_ts = ts.shape[0]\n",
    "\n",
    "    key, eval_key, sample_key = jr.split(key, 3)\n",
    "    # Evaluate the population on the data, and return the fitness\n",
    "    fitness, population = strategy.evaluate_population(population, (x0s, ts[:end_ts], ys[:,:end_ts]), eval_key)\n",
    "\n",
    "    # Print the best solution in the population in this generation\n",
    "    best_fitness, best_solution = strategy.get_statistics(g)\n",
    "    print(f\"In generation {g+1}, best fitness = {best_fitness:.4f}, best solution = {strategy.expression_to_string(best_solution)}\")\n",
    "\n",
    "    # Evolve the population until the last generation. The fitness should be given to the evolve function.\n",
    "    if g < (num_generations-1):\n",
    "        population = strategy.evolve_population(population, fitness, sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: 2, fitness: 3.4025232791900635, equations: [-0.193, -0.455]\n",
      "Complexity: 4, fitness: 2.334573268890381, equations: [-1.38*x0, -0.743]\n",
      "Complexity: 6, fitness: 1.192003607749939, equations: [-4.32*x0, -0.328*x1]\n",
      "Complexity: 8, fitness: 1.1891828775405884, equations: [-0.482*x0*x1, -0.33*x1]\n",
      "Complexity: 10, fitness: 1.099962830543518, equations: [-2.78*x0, x0 - 0.427*x1 + 0.0845]\n",
      "Complexity: 12, fitness: 0.8712133169174194, equations: [-0.396*x0*x1 + x0, x0 - 0.398*x1]\n",
      "Complexity: 14, fitness: 0.7701644897460938, equations: [-0.394*x0*x1 + x0, 0.318*x0 - 0.361*x1]\n",
      "Complexity: 16, fitness: 0.27488815784454346, equations: [-0.343*x0*x1 + x0, 0.0965*x0*x1 - 0.394*x1]\n",
      "Complexity: 18, fitness: 0.007773575372993946, equations: [-0.399*x0*(x1 - 2.75), 0.101*x0*x1 - 0.401*x1]\n",
      "Complexity: 22, fitness: 0.003365457523614168, equations: [-0.4*x0*(x1 - 2.75), 0.0998*x0*x1 - 0.399*x1]\n"
     ]
    }
   ],
   "source": [
    "strategy.print_pareto_front()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

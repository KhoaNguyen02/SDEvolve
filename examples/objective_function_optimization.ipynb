{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax \n",
    "\n",
    "from kozax.genetic_programming import GeneticProgramming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitnessFunction:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epochs, learning_rate):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.optim = optax.adam(learning_rate)\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def __call__(self, candidate, data, tree_evaluator):\n",
    "        data_keys, test_keys, network_keys = data\n",
    "        losses = jax.vmap(self.train, in_axes=[None, 0, 0, 0, None])(candidate, data_keys, test_keys, network_keys, tree_evaluator)\n",
    "        return jnp.mean(losses)\n",
    "\n",
    "    def get_data(self, key, n_samples = 50):\n",
    "        x = jr.uniform(key, shape=(n_samples, 2))\n",
    "        y = jnp.logical_xor(x[:,0]>0.5, x[:,1]>0.5)\n",
    "\n",
    "        return x, y[:,None]\n",
    "\n",
    "    def loss_function(self, params, x, y, candidate, tree_evaluator):\n",
    "        pred = self.neural_network(params, x)\n",
    "        return jnp.mean(jax.vmap(tree_evaluator, in_axes=[None, 0])(candidate, jnp.concatenate([pred, y], axis=-1)))\n",
    "    \n",
    "    def train(self, candidate, data_key, test_key, network_key, tree_evaluator):\n",
    "        params = self.init_network_params(network_key)\n",
    "\n",
    "        optim_state = self.optim.init(params)\n",
    "\n",
    "        def step(i, carry):\n",
    "            params, optim_state, key = carry\n",
    "\n",
    "            key, _key = jr.split(key)\n",
    "\n",
    "            x_train, y_train = self.get_data(_key, n_samples=100)\n",
    "\n",
    "            grads = jax.grad(self.loss_function)(params, x_train, y_train, candidate, tree_evaluator)\n",
    "                \n",
    "            # Update parameters\n",
    "            updates, optim_state = self.optim.update(grads, optim_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "\n",
    "            return (params, optim_state, key)\n",
    "\n",
    "        (params, _, _) = jax.lax.fori_loop(0, self.epochs, step, (params, optim_state, data_key))\n",
    "\n",
    "        x_test, y_test = self.get_data(test_key, n_samples=500)\n",
    "\n",
    "        pred = self.neural_network(params, x_test)\n",
    "        return 1 - jnp.mean(y_test==(pred>0.5))\n",
    "\n",
    "    # Define the neural network function (forward pass)\n",
    "    def neural_network(self, params, x):\n",
    "        w1, b1, w2, b2, w3, b3 = params\n",
    "        hidden = jnp.tanh(jnp.dot(x, w1) + b1)\n",
    "        hidden = jnp.tanh(jnp.dot(hidden, w2) + b2)\n",
    "        output = jnp.dot(hidden, w3) + b3\n",
    "        return jax.nn.sigmoid(output)\n",
    "\n",
    "    # Define the neural network model (1 hidden layer)\n",
    "    def init_network_params(self, key):\n",
    "        key1, key2, key3 = jr.split(key, 3)\n",
    "        w1 = jr.normal(key1, (self.input_dim, self.hidden_dim)) * jnp.sqrt(2.0 / self.input_dim)\n",
    "        b1 = jnp.zeros(self.hidden_dim)\n",
    "        w2 = jr.normal(key2, (self.hidden_dim, self.hidden_dim)) * jnp.sqrt(2.0 / self.hidden_dim)\n",
    "        b2 = jnp.zeros(self.hidden_dim)\n",
    "        w3 = jr.normal(key3, (self.hidden_dim, self.output_dim)) * jnp.sqrt(2.0 / self.hidden_dim)\n",
    "        b3 = jnp.zeros(self.output_dim)\n",
    "        return (w1, b1, w2, b2, w3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keys(key, batch_size=4):\n",
    "    key1, key2, key3 = jr.split(key, 3)\n",
    "    return jr.split(key1, batch_size), jr.split(key2, batch_size), jr.split(key3, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 100\n",
    "num_populations = 10\n",
    "num_generations = 50\n",
    "\n",
    "seeds = jnp.arange(10)\n",
    "\n",
    "operator_list = [(\"+\", lambda x, y: jnp.add(x, y), 2, 0.5), \n",
    "                (\"-\", lambda x, y: jnp.subtract(x, y), 2, 0.5),\n",
    "                (\"*\", lambda x, y: jnp.multiply(x, y), 2, 0.5),\n",
    "                (\"/\", lambda x, y: jnp.divide(x, y + 1e-7), 2, 0.1),\n",
    "                (\"**\", lambda x, y: jnp.power(x, y), 2, 0.1),\n",
    "                (\"log\", lambda x: jnp.log(x + 1e-7), 1, 0.1),\n",
    "                (\"exp\", lambda x: jnp.exp(x), 1, 0.1)\n",
    "                ]\n",
    "\n",
    "variable_list = [[\"pred\", \"y\"]]\n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1\n",
    "\n",
    "fitness_function = FitnessFunction(input_dim, hidden_dim, output_dim, learning_rate=0.01, epochs=500)\n",
    "\n",
    "strategy = GeneticProgramming(num_generations, population_size, fitness_function, operator_list, variable_list, num_populations = num_populations,\n",
    "            max_nodes = 15, coefficient_optimisation=None, migration_period=5, size_parsimony=0.003)\n",
    "\n",
    "for seed in seeds:\n",
    "    strategy.reset()\n",
    "    key = jr.PRNGKey(seed)\n",
    "    print(f\"Seed: {seed}\")\n",
    "\n",
    "    data_key, init_key = jr.split(key)\n",
    "    data_keys, test_keys, network_keys = generate_keys(data_key)\n",
    "\n",
    "    population = strategy.initialize_population(init_key)\n",
    "\n",
    "    for g in range(num_generations):\n",
    "        key, eval_key, sample_key = jr.split(key, 3)\n",
    "        fitness, population = strategy.evaluate_population(population, (data_keys, test_keys, network_keys), eval_key)\n",
    "\n",
    "        if g < (num_generations-1):\n",
    "            \n",
    "            population = strategy.evolve(population, fitness, sample_key)\n",
    "\n",
    "    strategy.print_pareto_front()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

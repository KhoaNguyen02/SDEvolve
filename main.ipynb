{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from jax.random import PRNGKey\n",
    "import diffrax\n",
    "import copy\n",
    "from typing import Tuple, Sequence\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import time\n",
    "\n",
    "from expression import Expression\n",
    "from environments.cart_pole import CartPole\n",
    "from environments.stochastic_harmonic_oscillator import StochasticHarmonicOscillator\n",
    "from networkTrees import NetworkTrees\n",
    "import reproduction, miscellaneous, simplification, migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_expressions(state_size, obs_size, control_size):\n",
    "    binary_operators_map = {\"+\":lambda a,b:a+b, \"-\":lambda a,b:a-b, \"*\":lambda a,b:a*b, \"/\":lambda a,b:a/b, \"**\":lambda a,b:a**b}\n",
    "    unary_operators_map = {\"sin\":lambda a:jnp.sin(a), \"cos\":lambda a:jnp.cos(a)}#,\"exp\":lambda a:jnp.clip(jnp.exp(a),a_max=100), \"sqrt\":lambda a:jnp.sqrt(jnp.abs(a))}\n",
    "\n",
    "    variables = [\"y\" + str(i) for i in range(obs_size)]\n",
    "    state_variables = [\"a\" + str(i) for i in range(state_size)]\n",
    "    control_variables = [\"u\" + str(i) for i in range(control_size)]\n",
    "\n",
    "    return Expression(binary_operators_map, unary_operators_map, variables, state_variables, control_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, env, expressions, state_size, key, dt, T, parsimony = 0.2, batch_size = 32):\n",
    "        self.env = env\n",
    "        self.expressions = expressions\n",
    "        self.state_size = state_size\n",
    "        self.latent_size = self.env.n_var\n",
    "        self.parsimony = parsimony\n",
    "\n",
    "        self.data = self.get_data(batch_size, key, self.latent_size, dt, T, env.mu0, env.P0)\n",
    "\n",
    "    def get_data(self, batch_size, key, n_var, dt, T, mu0, P0):\n",
    "        init_key, target_key, noise_key, param1_key, param2_key = jrandom.split(key, 5)\n",
    "        x0 = mu0 + jrandom.normal(init_key, shape=(batch_size,n_var))@P0\n",
    "        targets = jrandom.uniform(target_key, shape=(batch_size,), minval=-10, maxval=10)\n",
    "        noise_keys = jrandom.split(noise_key, batch_size)\n",
    "        omegas = jrandom.uniform(param1_key, shape=(batch_size,), minval=0.5, maxval=1.5)\n",
    "        zetas = jrandom.uniform(param2_key, shape=(batch_size,), minval=0.0, maxval=0.5)\n",
    "        ts = jnp.arange(0,T,dt)\n",
    "        # omegas = jnp.ones(N)\n",
    "        params = omegas, zetas\n",
    "        return x0, ts, targets, noise_keys, params\n",
    "\n",
    "    #Evaluation methods\n",
    "    def evaluate_tree(self, tree: list):\n",
    "        \"A tree is transformed to a callable function, represented as nested lamba functions\"\n",
    "        if tree[0] in self.expressions.binary_operators:\n",
    "            assert len(tree) == 3, f\"The operator {tree[0]} requires two inputs\"\n",
    "            left = self.evaluate_tree(tree[1])\n",
    "            right = self.evaluate_tree(tree[2])\n",
    "            return lambda x, a, u, t: self.expressions.binary_operators_map[tree[0]](left(x,a,u,t),right(x,a,u,t))\n",
    "        \n",
    "        elif tree[0] in self.expressions.unary_operators:\n",
    "            assert len(tree) == 2, f\"The operator {tree[0]} requires one input\"\n",
    "            left = self.evaluate_tree(tree[1])\n",
    "            return lambda x, a, u, t: self.expressions.unary_operators_map[tree[0]](left(x,a,u,t))\n",
    "\n",
    "        assert len(tree) == 1, \"Leaves should not have children\"\n",
    "        if isinstance(tree[0],jax.numpy.ndarray):\n",
    "            return lambda x, a, u, t: tree[0]\n",
    "        elif tree[0]==\"target\":\n",
    "            return lambda x, a, u, t: t\n",
    "        elif tree[0] in self.expressions.state_variables:\n",
    "            return lambda x, a, u, t: a[self.expressions.state_variables.index(tree[0])]\n",
    "        elif tree[0] in self.expressions.variables:\n",
    "            return lambda x, a, u, t: x[self.expressions.variables.index(tree[0])]\n",
    "        elif tree[0] in self.expressions.control_variables:\n",
    "            return lambda x, a, u, t: u[self.expressions.control_variables.index(tree[0])]\n",
    "        print(tree)\n",
    "    \n",
    "    def evaluate_trees(self, trees: NetworkTrees):\n",
    "        \"Evaluate the trees in the network\"\n",
    "        return [self.evaluate_tree(tree) for tree in trees()]\n",
    "   \n",
    "    def evaluate_control_loop(self, model: Tuple, x0: Sequence[float], ts: Sequence[float], target: float, key: PRNGKey, params: Tuple):\n",
    "        \"\"\"Solves the coupled differential equation of the system and controller. The differential equation of the system is defined in the environment and the differential equation of the control is defined by the set of trees\n",
    "        Inputs:\n",
    "            model (NetworkTrees): Model with trees for the hidden state and readout\n",
    "            x0 (float): Initial state of the system\n",
    "            ts (Array[float]): time points on which the controller is evaluated\n",
    "            target (float): Target position that the system should reach\n",
    "            key (PRNGKey)\n",
    "            params (Tuple[float]): Parameters that define the system\n",
    "\n",
    "        Returns:\n",
    "            xs (Array[float]): States of the system at every time point\n",
    "            ys (Array[float]): Observations of the system at every time point\n",
    "            us (Array[float]): Control of the model at every time point\n",
    "            activities (Array[float]): Activities of the hidden state of the model at every time point\n",
    "            fitness (float): Fitness of the model \n",
    "        \"\"\"\n",
    "        env = copy.copy(self.env)\n",
    "        env.initialize_parameters(params)\n",
    "\n",
    "        state_equation, readout = model\n",
    "\n",
    "        #Define state equation\n",
    "        def _drift(t, x_a, args):\n",
    "            x = x_a[:self.latent_size]\n",
    "            a = x_a[self.latent_size:]\n",
    "\n",
    "            # jax.debug.print(\"P={P}\", P=a[2:])\n",
    "\n",
    "            y = env.f_obs(t, x) #Get observations from system\n",
    "            u = readout(y, a, 0, target) #Readout control from hidden state\n",
    "            # u = a\n",
    "            \n",
    "            dx = env.drift(t, x, u) #Apply control to system and get system change\n",
    "            da = state_equation(y, a, u, target) #Compute hidden state updates\n",
    "            return jnp.concatenate([dx, da])\n",
    "        \n",
    "        #Define diffusion\n",
    "        def _diffusion(t, x_a, args):\n",
    "            x = x_a[:self.latent_size]\n",
    "            a = x_a[self.latent_size:]\n",
    "            y = env.f_obs(t, x)\n",
    "            u = jnp.array([readout(y, a, 0, target)])\n",
    "            # u = a\n",
    "            return jnp.concatenate([env.diffusion(t, x, u), jnp.zeros((self.state_size, self.latent_size))]) #Only the system is stochastic\n",
    "        \n",
    "        solver = diffrax.Euler()\n",
    "        dt0 = 0.005\n",
    "        saveat = diffrax.SaveAt(ts=ts)\n",
    "        _x0 = jnp.concatenate([x0, jnp.zeros(self.state_size)])\n",
    "        # _x0 = jnp.concatenate([x0, jnp.zeros(2), jnp.array([1,0,0,1])*self.env.obs_noise])\n",
    "\n",
    "        brownian_motion = diffrax.UnsafeBrownianPath(shape=(self.latent_size,), key=key)\n",
    "        system = diffrax.MultiTerm(diffrax.ODETerm(_drift), diffrax.ControlTerm(_diffusion, brownian_motion))\n",
    "\n",
    "        sol = diffrax.diffeqsolve(\n",
    "            system, solver, ts[0], ts[-1], dt0, _x0, saveat=saveat, adjoint=diffrax.DirectAdjoint(), max_steps=16**4\n",
    "        )\n",
    "        xs = sol.ys[:,:self.latent_size]\n",
    "        ys = jax.vmap(env.f_obs)(ts, xs) #Map states to observations\n",
    "        activities = sol.ys[:,self.latent_size:]\n",
    "        \n",
    "        us = jax.vmap(readout, in_axes=[0,0,None,None])(ys, activities, jnp.array([0]), target) #Map hidden state to control \n",
    "        # us = activities   \n",
    "        # fitness = jax.lax.cond(jnp.isnan(us).any(),lambda x, u, t: 1e3*jnp.ones(ts.shape), lambda x, u, t: env.fitness_function(x, u, t), xs, us, target) #Compute fitness with cost function in the environment\n",
    "        fitness = env.fitness_function(xs, us, target)\n",
    "\n",
    "        return xs, ys, us, activities, fitness\n",
    "\n",
    "    def get_fitness(self, model: NetworkTrees, add_regularization: bool = True):\n",
    "        \"Determine the fitness of a tree\"\n",
    "        _, _, _, _, fitness = self.evaluate_model(model)\n",
    "\n",
    "        fitness = jnp.mean(fitness[:,-1])\n",
    "        \n",
    "        if jnp.isinf(fitness) or jnp.isnan(fitness):\n",
    "            fitness = jnp.array(1e6)\n",
    "        if add_regularization: #Add regularization to punish trees for their size\n",
    "            return jnp.clip(fitness + self.parsimony*len(jax.tree_util.tree_leaves(model)),0,1e6)\n",
    "        else:\n",
    "            return jnp.clip(fitness,0,1e6)\n",
    "        \n",
    "    def evaluate_model(self, model: NetworkTrees):\n",
    "        \"Evaluate a tree by simulating the environment and controller as a coupled system\"\n",
    "        \n",
    "        #Trees to callable functions\n",
    "        tree_funcs = self.evaluate_trees(model)\n",
    "        state_equation = jax.jit(lambda y, a, u, tar: jnp.array([tree_funcs[i](y, a, u, tar) for i in range(self.state_size)]))\n",
    "        readout_layer = self.evaluate_tree(model.readout_tree)\n",
    "        readout = lambda y, a, _, tar: jnp.atleast_1d([readout_layer(y, a, _, tar)])\n",
    "        model = (state_equation, readout)\n",
    "\n",
    "        x0, ts, targets, noise_keys, params = self.data\n",
    "        return jax.vmap(self.evaluate_control_loop, in_axes=[None, 0, None, 0, 0, 0])(model, x0, ts, targets, noise_keys, params) #Run coupled differential equations of state and control and get fitness of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(0)\n",
    "env_key, data_key = jrandom.split(key)\n",
    "\n",
    "population_size = 100\n",
    "num_populations = 4\n",
    "num_generations = 5\n",
    "state_size = 3\n",
    "T = 150\n",
    "dt = 0.5\n",
    "pool_size = 10\n",
    "continue_population = None\n",
    "restart_iter_threshold = jnp.array([10,8,6,4])\n",
    "migration_period = 5\n",
    "\n",
    "sigma = 0.01\n",
    "obs_noise = 0.1\n",
    "\n",
    "env = StochasticHarmonicOscillator(env_key, sigma, obs_noise, n_obs=2)\n",
    "expressions = define_expressions(state_size, env.n_obs, env.n_control)\n",
    "evaluator = Evaluator(env, expressions, state_size, data_key, dt, T)\n",
    "reproducer = reproduction.Reproducer(expressions, population_size, state_size, num_populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generation 1, average fitness: 740285.6875, best_fitness: 4023.35546875, best solution: [y0, a0, u0], readout: target\n",
      "In generation 2, average fitness: 421872.0, best_fitness: 3882.2001953125, best solution: [y0**u0 - 0.13257317, (3.9216335**(3.0638118*u0 + y0*y1))**a1, ((u0 + 1.4091525)**(y0*(a1 + y0) - 1.8646204) + 1)*(-a0 - a1 - 1.9596444*u0)/(target + u0**y1 + y1)], readout: target - 0.1525118\n",
      "In generation 3, average fitness: 233081.75, best_fitness: 3547.604736328125, best solution: [u0**(-2.3780227), 1.98754810000000, y0 - y1], readout: 0.7232*target\n",
      "In generation 4, average fitness: 324799.40625, best_fitness: 3530.1904296875, best solution: [2.1172884**y0, 0.899062000000000, target], readout: 0.848090388795166*target\n",
      "Final generation, average fitness: 308866.875, best_fitness: 3530.1904296875, best solution: [2.1172884**y0, 0.899062000000000, target], readout: 0.848090388795166*target\n"
     ]
    }
   ],
   "source": [
    "n_seeds = 1\n",
    "\n",
    "best_fitnesses = jnp.zeros((n_seeds, num_generations))\n",
    "best_solutions = []\n",
    "# rs_best_fitnesses = []\n",
    "# rs_best_solutions = []\n",
    "# all_costs_lqr = []\n",
    "# all_costs_lqg = []\n",
    "\n",
    "for seed in range(0,n_seeds):\n",
    "    pool = Pool(pool_size)  \n",
    "    pool.close()\n",
    "\n",
    "    best_solution = None\n",
    "    best_fitness = jnp.inf\n",
    "    best_fitness_per_population = jnp.zeros((num_generations, num_populations))\n",
    "\n",
    "    last_restart = jnp.zeros(num_populations)\n",
    "\n",
    "    if continue_population is None:\n",
    "        #Initialize new population\n",
    "        key, new_key = jrandom.split(key)\n",
    "        populations = reproducer.sample_trees(new_key, population_size, num_populations=num_populations)\n",
    "    else:\n",
    "        #Continue from a previous population\n",
    "        populations = continue_population\n",
    "    \n",
    "    for g in range(num_generations):\n",
    "        pool.restart()\n",
    "        fitness = pool.amap(lambda x: evaluator.get_fitness(x),miscellaneous.flatten(populations)) #Evaluate each solution parallely on a pool of workers\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        tries = 0\n",
    "        while not fitness.ready():\n",
    "            time.sleep(1)\n",
    "            tries += 1\n",
    "\n",
    "            if tries >= 200:\n",
    "                print(\"TIMEOUT\")\n",
    "                break\n",
    "\n",
    "        flat_fitnesses = jnp.array(fitness.get())\n",
    "        fitnesses = jnp.reshape(flat_fitnesses,(num_populations,population_size))\n",
    "        # print(jnp.mean(fitnesses, axis=1),jnp.min(fitnesses, axis=1))\n",
    "\n",
    "        best_fitness_per_population = best_fitness_per_population.at[g].set(jnp.min(fitnesses, axis=1))\n",
    "        \n",
    "        #Set the fitness of each solution\n",
    "        for pop in range(num_populations):\n",
    "            population = populations[pop]\n",
    "            for candidate in range(population_size):\n",
    "                population[candidate].set_fitness(fitnesses[pop,candidate])\n",
    "\n",
    "        best_solution_of_g = miscellaneous.best_solution(populations, fitnesses)\n",
    "        best_fitness_at_g = evaluator.get_fitness(best_solution_of_g, add_regularization=False)\n",
    "        if best_fitness_at_g < best_fitness:\n",
    "            best_fitness = best_fitness_at_g\n",
    "            best_solution = best_solution_of_g\n",
    "        best_fitnesses = best_fitnesses.at[seed, g].set(best_fitness)\n",
    "\n",
    "        if best_fitnesses[seed, g]==best_fitnesses[seed, g-2]: #A solution reached a satisfactory score\n",
    "            best_solution_string = simplification.trees_to_sympy(best_solution)\n",
    "            print(f\"Converge settings satisfied, best fitness {best_fitness}, best solution: {best_solution_string}, readout: {simplification.tree_to_sympy(best_solution.readout_tree)}\")\n",
    "            best_fitnesses = best_fitnesses.at[g:].set(best_fitness)\n",
    "\n",
    "            break\n",
    "\n",
    "        elif g < num_generations-1: #The final generation has not been reached yet, so a new population is sampled\n",
    "            best_solution_string = simplification.trees_to_sympy(best_solution)\n",
    "            print(f\"In generation {g+1}, average fitness: {jnp.mean(fitnesses)}, best_fitness: {best_fitness}, best solution: {best_solution_string}, readout: {simplification.tree_to_sympy(best_solution.readout_tree)}\")\n",
    "\n",
    "            #Migrate individuals between populations every few generations\n",
    "            if ((g+1)%migration_period)==0:\n",
    "                populations = migration.migrate_populations(populations)\n",
    "\n",
    "            last_restart = last_restart + 1\n",
    "                            \n",
    "            for pop in range(num_populations):\n",
    "                #Generate new population\n",
    "                key, new_key = jrandom.split(key)\n",
    "                if last_restart[pop]>restart_iter_threshold[pop] and best_fitness_per_population[g,pop] >= best_fitness_per_population[g-restart_iter_threshold[pop],pop]:\n",
    "                    print(f\"Stuck restart in population {pop+1}\")\n",
    "                    populations[pop] = reproducer.sample_trees(new_key, population_size, num_populations=1)[0]\n",
    "                    last_restart = last_restart.at[pop].set(0)\n",
    "                else:\n",
    "                    populations[pop] = reproducer.next_population(populations[pop], jnp.mean(flat_fitnesses), pop, new_key)\n",
    "            \n",
    "        else: #Final generation is reached\n",
    "            best_solution_string = simplification.trees_to_sympy(best_solution)\n",
    "            print(f\"Final generation, average fitness: {jnp.mean(fitnesses)}, best_fitness: {best_fitness}, best solution: {best_solution_string}, readout: {simplification.tree_to_sympy(best_solution.readout_tree)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
